from utils.load_data import load_bib_data as load_data
from sentence_transformers import SentenceTransformer, util
import random

# ===============================
# 1Ô∏è‚É£ Cargar datos
# ===============================
print("üìö Cargando datos...")
df = load_data("data")

# Filtrar art√≠culos con resumen
df_valid = df[df["resumen"].str.strip() != ""]
print(f"Art√≠culos con resumen v√°lido: {len(df_valid)}\n")

# ===============================
# 2Ô∏è‚É£ Seleccionar dos res√∫menes aleatorios
# ===============================
sample = df_valid.sample(2, random_state=random.randint(1, 9999))
abstracts = sample["resumen"].tolist()

print("Abstract 1:", abstracts[0][:200], "...\n")
print("Abstract 2:", abstracts[1][:200], "...\n")

# ===============================
# 3Ô∏è‚É£ Modelos IA (Sentence-BERT)
# ===============================
print("üîπ Cargando modelos de similitud IA...\n")

# Modelo 1: all-MiniLM-L6-v2
model1 = SentenceTransformer("all-MiniLM-L6-v2")

# Modelo 2: paraphrase-MiniLM-L12-v2
model2 = SentenceTransformer("paraphrase-MiniLM-L12-v2")

# ===============================
# 4Ô∏è‚É£ Codificar y calcular similitudes
# ===============================
embeddings1 = model1.encode(abstracts, convert_to_tensor=True)
embeddings2 = model2.encode(abstracts, convert_to_tensor=True)

sim1 = util.pytorch_cos_sim(embeddings1[0], embeddings1[1]).item()
sim2 = util.pytorch_cos_sim(embeddings2[0], embeddings2[1]).item()

print(f"üîπ Similitud Sem√°ntica (SBERT - all-MiniLM-L6-v2): {sim1:.3f}")
print(f"üîπ Similitud Sem√°ntica (SBERT - paraphrase-MiniLM-L12-v2): {sim2:.3f}")
